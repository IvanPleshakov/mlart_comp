{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imorts and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = Path('train.csv')\n",
    "R_TRAIN_DATASET = Path('./data/train_256/')\n",
    "R_TEST_DATASET = Path('./data/test_256/')\n",
    "BEST_SUBMISSION = Path('./submissoins/subm_best6.csv')\n",
    "SAVE_MODELS_DIR = Path('./models/vitbasefold_vhaugs')\n",
    "USE_TEST_IN_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark     = False\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, delimiter=\"\\t\")\n",
    "df.image_name = df.image_name.apply(lambda x: x.split(\".\")[0] + \".jpg\")\n",
    "df[\"path\"] = df[\"image_name\"].apply(lambda x: R_TRAIN_DATASET / x)\n",
    "df = df.sample(frac=1, random_state=SEED)\n",
    "\n",
    "if USE_TEST_IN_TRAIN:\n",
    "    df_test = pd.read_csv(BEST_SUBMISSION, delimiter=\"\\t\")\n",
    "    df_test.image_name = df_test.image_name.apply(lambda x: x.split(\".\")[0] + \".jpg\")\n",
    "    df_test[\"path\"] = df_test[\"image_name\"].apply(lambda x: R_TEST_DATASET / x)\n",
    "    df = pd.concat([df, df_test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsTransform(DisplayedTransform):\n",
    "    split_idx, order = 0, 2\n",
    "\n",
    "    def __init__(self, train_aug):\n",
    "        store_attr()\n",
    "\n",
    "    def encodes(self, img: PILImage):\n",
    "        aug_img = self.train_aug(image=np.array(img))[\"image\"]\n",
    "        return PILImage.create(aug_img)\n",
    "\n",
    "\n",
    "def A_augs():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.ColorJitter(hue=0.1, p=0.5),\n",
    "            A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=0.5),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.6),\n",
    "            A.CoarseDropout(p=0.5),\n",
    "            A.PixelDropout(0.005, p=0.5),\n",
    "            A.Downscale(scale_min=0.75, scale_max=0.9, interpolation=4, p=0.3),\n",
    "            A.ImageCompression(quality_lower=45, quality_upper=85, p=0.3),\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
    "            A.CLAHE(clip_limit=(1, 6), p=0.3),\n",
    "            A.Sharpen(alpha=(0.1, 0.5), lightness=(0.5, 1.0), p=0.3),\n",
    "            A.RandomGridShuffle(grid=(3, 3), p=0.1),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train k Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(\n",
    "    skf.split(np.zeros(len(df)), df[\"label_id\"])\n",
    "):\n",
    "    print(f\"\\nFold {i}\")\n",
    "\n",
    "    df[\"isVal\"] = False\n",
    "    df.loc[val_index, \"isVal\"] = True\n",
    "\n",
    "    datablock = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock),\n",
    "        get_x=ColReader(\"path\"),\n",
    "        get_y=ColReader(\"label_id\"),\n",
    "        splitter=ColSplitter(\"isVal\"),\n",
    "        item_tfms=AlbumentationsTransform(A_augs()),\n",
    "        batch_tfms=aug_transforms(\n",
    "            mult=2,\n",
    "            min_scale=1,\n",
    "            size=224,\n",
    "        ),\n",
    "    )\n",
    "    dls = datablock.dataloaders(df, bs=32)\n",
    "\n",
    "    learn = vision_learner(\n",
    "        dls,\n",
    "        \"vit_base_patch16_224_in21k\",\n",
    "        opt_func=QHAdam,\n",
    "        metrics=[F1Score(average=\"macro\")],\n",
    "    )\n",
    "\n",
    "    filename = \"model\"\n",
    "    learn.fine_tune(\n",
    "        10,\n",
    "        1e-3,\n",
    "        freeze_epochs=1,\n",
    "        cbs=[\n",
    "            SaveModelCallback(monitor=\"f1_score\", fname=filename, at_end=True),\n",
    "        ],\n",
    "    )\n",
    "    learn.export(SAVE_MODELS_DIR / f\"model_{i}.pkl\")\n",
    "\n",
    "    del learn, dls\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f9285ea335aa6ad6901a41d37b03ab44602c19922b969a93c46c068fbeb770c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
